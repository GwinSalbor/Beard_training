{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/yarosalv/Documents/Untitled/venv1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yarosalv/Documents/Untitled/venv1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yarosalv/Documents/Untitled/venv1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yarosalv/Documents/Untitled/venv1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yarosalv/Documents/Untitled/venv1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yarosalv/Documents/Untitled/venv1/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "    SeparableConv2D, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import initializers\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "from keras import applications\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "import tensorflow as tf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"./dataset/labels_for_test.json\"\n",
    "with open(labels) as label:\n",
    "    data = json.load(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(labels):\n",
    "    data = {}\n",
    "    for key in labels.keys():\n",
    "        if labels[key] not in data:\n",
    "            data.update({labels[key]: []})\n",
    "        data[labels[key]].append(key)\n",
    "    return data\n",
    "data  = data_prepare(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "for i in data:\n",
    "    if len(data[i]) > max_len:\n",
    "        max_len = len(data[i])\n",
    "    train_data.update({i: data[i][:int(0.9*len(data[i]))]})\n",
    "    val_data.update({i: data[i][int(0.9*len(data[i])):]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder with train data classic_long prepared\n",
      "Folder with train data goatee prepared\n",
      "Folder with train data goatee_with_moustache prepared\n",
      "Folder with train data classic_short prepared\n",
      "Folder with train data moustache prepared\n",
      "Folder with train data shaven prepared\n",
      "Folder with train data stubble prepared\n",
      "Folder with train data chin_curtain prepared\n",
      "Folder with validation data classic_long prepared\n",
      "Folder with validation data goatee prepared\n",
      "Folder with validation data goatee_with_moustache prepared\n",
      "Folder with validation data classic_short prepared\n",
      "Folder with validation data moustache prepared\n",
      "Folder with validation data shaven prepared\n",
      "Folder with validation data stubble prepared\n",
      "Folder with validation data chin_curtain prepared\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.8),\n",
    "    sometimes(iaa.Affine(\n",
    "    rotate=(-18, 18),\n",
    ")),\n",
    "])\n",
    "\n",
    "\n",
    "for label in train_data:\n",
    "    if not os.path.exists('dataset/learning_data/' + label):\n",
    "        os.makedirs('dataset/learning_data/' + label)\n",
    "        for i, img_name in enumerate(train_data[label]):\n",
    "            image = cv2.imread('dataset/data_for_test/' +  img_name)\n",
    "            gray = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), (img_width, img_height))\n",
    "            cv2.imwrite('dataset/learning_data/' + label + \"/\" + str(i) +\".jpg\", gray)\n",
    "        for i in range(max_len-len(train_data[label])):\n",
    "            image = cv2.imread('dataset/data_for_test/' + random.choice(train_data[label]))\n",
    "            gray = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), (img_width, img_height))\n",
    "            images_aug = seq(images=gray)\n",
    "            cv2.imwrite('dataset/learning_data/' + label + \"/\" + str(len(train_data[label]) + i) +\".jpg\", images_aug)\n",
    "    else:\n",
    "        print(\"Folder with train data {} prepared\".format(label))\n",
    "\n",
    "for label in val_data:\n",
    "    if not os.path.exists('dataset/validation_data/' + label):\n",
    "        os.makedirs('dataset/validation_data/' + label)\n",
    "        for i, img_name in enumerate(val_data[label]):\n",
    "            image = cv2.imread('dataset/data_for_test/' +  img_name)\n",
    "            gray = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), (img_width, img_height))\n",
    "            cv2.imwrite('dataset/validation_data/' + label + \"/\" + str(i) +\".jpg\", gray)\n",
    "    else:\n",
    "        print(\"Folder with validation data {} prepared\".format(label))\n",
    "\n",
    "        \n",
    "del(val_data)\n",
    "del(train_data)\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2408 images belonging to 8 classes.\n",
      "Found 205 images belonging to 8 classes.\n",
      "Epoch 1/50\n",
      "301/301 [==============================] - 32s 106ms/step - loss: 2.0501 - acc: 0.1935 - val_loss: 1.9969 - val_acc: 0.1951\n",
      "Epoch 2/50\n",
      "301/301 [==============================] - 29s 97ms/step - loss: 1.8616 - acc: 0.2986 - val_loss: 1.9709 - val_acc: 0.2341\n",
      "Epoch 3/50\n",
      "301/301 [==============================] - 30s 101ms/step - loss: 1.7467 - acc: 0.3434 - val_loss: 2.0719 - val_acc: 0.2049\n",
      "Epoch 4/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 1.6859 - acc: 0.3650 - val_loss: 1.8304 - val_acc: 0.3220\n",
      "Epoch 5/50\n",
      "301/301 [==============================] - 31s 103ms/step - loss: 1.5911 - acc: 0.4165 - val_loss: 1.9133 - val_acc: 0.2585\n",
      "Epoch 6/50\n",
      "301/301 [==============================] - 31s 103ms/step - loss: 1.5956 - acc: 0.4020 - val_loss: 1.8714 - val_acc: 0.3024\n",
      "Epoch 7/50\n",
      "301/301 [==============================] - 30s 101ms/step - loss: 1.5122 - acc: 0.4340 - val_loss: 1.8506 - val_acc: 0.2829\n",
      "Epoch 8/50\n",
      "301/301 [==============================] - 31s 103ms/step - loss: 1.4456 - acc: 0.4713 - val_loss: 1.9219 - val_acc: 0.3171\n",
      "Epoch 9/50\n",
      "301/301 [==============================] - 31s 102ms/step - loss: 1.4363 - acc: 0.4718 - val_loss: 1.7953 - val_acc: 0.3024\n",
      "Epoch 10/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 1.3762 - acc: 0.4934 - val_loss: 1.8318 - val_acc: 0.2878\n",
      "Epoch 11/50\n",
      "301/301 [==============================] - 31s 101ms/step - loss: 1.3603 - acc: 0.5087 - val_loss: 2.1221 - val_acc: 0.2195\n",
      "Epoch 12/50\n",
      "301/301 [==============================] - 30s 101ms/step - loss: 1.3112 - acc: 0.5166 - val_loss: 1.8627 - val_acc: 0.2293\n",
      "Epoch 13/50\n",
      "301/301 [==============================] - 31s 104ms/step - loss: 1.2748 - acc: 0.5403 - val_loss: 1.8242 - val_acc: 0.2780\n",
      "Epoch 14/50\n",
      "301/301 [==============================] - 31s 101ms/step - loss: 1.2475 - acc: 0.5540 - val_loss: 1.9138 - val_acc: 0.2732\n",
      "Epoch 15/50\n",
      "301/301 [==============================] - 30s 101ms/step - loss: 1.2230 - acc: 0.5565 - val_loss: 1.8803 - val_acc: 0.2829\n",
      "Epoch 16/50\n",
      "301/301 [==============================] - 31s 101ms/step - loss: 1.1867 - acc: 0.5644 - val_loss: 1.8522 - val_acc: 0.3122\n",
      "Epoch 17/50\n",
      "301/301 [==============================] - 29s 97ms/step - loss: 1.1467 - acc: 0.5963 - val_loss: 1.8391 - val_acc: 0.3073\n",
      "Epoch 18/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 1.1121 - acc: 0.6076 - val_loss: 1.8539 - val_acc: 0.3220\n",
      "Epoch 19/50\n",
      "301/301 [==============================] - 30s 101ms/step - loss: 1.0767 - acc: 0.6163 - val_loss: 1.8618 - val_acc: 0.3024\n",
      "Epoch 20/50\n",
      "301/301 [==============================] - 29s 95ms/step - loss: 1.0528 - acc: 0.6154 - val_loss: 1.9962 - val_acc: 0.2878\n",
      "Epoch 21/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 1.0224 - acc: 0.6387 - val_loss: 1.8945 - val_acc: 0.3171\n",
      "Epoch 22/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 1.0164 - acc: 0.6395 - val_loss: 1.9137 - val_acc: 0.3122\n",
      "Epoch 23/50\n",
      "301/301 [==============================] - 29s 95ms/step - loss: 0.9548 - acc: 0.6603 - val_loss: 1.9861 - val_acc: 0.3366\n",
      "Epoch 24/50\n",
      "301/301 [==============================] - 29s 97ms/step - loss: 0.9675 - acc: 0.6595 - val_loss: 1.8364 - val_acc: 0.3610\n",
      "Epoch 25/50\n",
      "301/301 [==============================] - 31s 102ms/step - loss: 0.9196 - acc: 0.6719 - val_loss: 1.9355 - val_acc: 0.3073\n",
      "Epoch 26/50\n",
      "301/301 [==============================] - 31s 102ms/step - loss: 0.8959 - acc: 0.6815 - val_loss: 1.9261 - val_acc: 0.3366\n",
      "Epoch 27/50\n",
      "301/301 [==============================] - 31s 101ms/step - loss: 0.8676 - acc: 0.6948 - val_loss: 1.9611 - val_acc: 0.3317\n",
      "Epoch 28/50\n",
      "301/301 [==============================] - 29s 98ms/step - loss: 0.8319 - acc: 0.7081 - val_loss: 1.9554 - val_acc: 0.3366\n",
      "Epoch 29/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 0.8011 - acc: 0.7147 - val_loss: 2.0775 - val_acc: 0.3366\n",
      "Epoch 30/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 0.7834 - acc: 0.7255 - val_loss: 1.9841 - val_acc: 0.2976\n",
      "Epoch 31/50\n",
      "301/301 [==============================] - 29s 97ms/step - loss: 0.7550 - acc: 0.7317 - val_loss: 2.0611 - val_acc: 0.2878\n",
      "Epoch 32/50\n",
      "301/301 [==============================] - 29s 97ms/step - loss: 0.7418 - acc: 0.7425 - val_loss: 2.1080 - val_acc: 0.3366\n",
      "Epoch 33/50\n",
      "301/301 [==============================] - 30s 101ms/step - loss: 0.6949 - acc: 0.7575 - val_loss: 2.0252 - val_acc: 0.3756\n",
      "Epoch 34/50\n",
      "301/301 [==============================] - 29s 98ms/step - loss: 0.6946 - acc: 0.7562 - val_loss: 2.0001 - val_acc: 0.3366\n",
      "Epoch 35/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 0.6657 - acc: 0.7778 - val_loss: 2.0962 - val_acc: 0.3268\n",
      "Epoch 36/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 0.6639 - acc: 0.7716 - val_loss: 2.1257 - val_acc: 0.2927\n",
      "Epoch 37/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 0.6348 - acc: 0.7824 - val_loss: 2.0995 - val_acc: 0.3317\n",
      "Epoch 38/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 0.5843 - acc: 0.7973 - val_loss: 2.2344 - val_acc: 0.2829\n",
      "Epoch 39/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 0.5735 - acc: 0.8140 - val_loss: 2.1871 - val_acc: 0.3171\n",
      "Epoch 40/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 0.5611 - acc: 0.8094 - val_loss: 2.2146 - val_acc: 0.3366\n",
      "Epoch 41/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 0.5316 - acc: 0.8239 - val_loss: 2.4269 - val_acc: 0.3463\n",
      "Epoch 42/50\n",
      "301/301 [==============================] - 31s 102ms/step - loss: 0.5087 - acc: 0.8260 - val_loss: 2.2034 - val_acc: 0.3415\n",
      "Epoch 43/50\n",
      "301/301 [==============================] - 29s 97ms/step - loss: 0.4781 - acc: 0.8447 - val_loss: 2.3687 - val_acc: 0.3024\n",
      "Epoch 44/50\n",
      "301/301 [==============================] - 29s 98ms/step - loss: 0.4773 - acc: 0.8389 - val_loss: 2.2367 - val_acc: 0.3463\n",
      "Epoch 45/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 0.4475 - acc: 0.8547 - val_loss: 2.3829 - val_acc: 0.3171\n",
      "Epoch 46/50\n",
      "301/301 [==============================] - 30s 100ms/step - loss: 0.4141 - acc: 0.8713 - val_loss: 2.2634 - val_acc: 0.3512\n",
      "Epoch 47/50\n",
      "301/301 [==============================] - 29s 98ms/step - loss: 0.4008 - acc: 0.8762 - val_loss: 2.4867 - val_acc: 0.3415\n",
      "Epoch 48/50\n",
      "301/301 [==============================] - 30s 98ms/step - loss: 0.3800 - acc: 0.8779 - val_loss: 2.5642 - val_acc: 0.3463\n",
      "Epoch 49/50\n",
      "301/301 [==============================] - 29s 98ms/step - loss: 0.3710 - acc: 0.8870 - val_loss: 2.4599 - val_acc: 0.3122\n",
      "Epoch 50/50\n",
      "301/301 [==============================] - 30s 99ms/step - loss: 0.3709 - acc: 0.8775 - val_loss: 2.4832 - val_acc: 0.3707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3699256ac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = \"dataset/learning_data/\"\n",
    "validation_data_dir = \"dataset/validation_data/\"\n",
    "nb_validation_samples = 2\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu',\n",
    "          kernel_initializer=initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None))(x)\n",
    "\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "nb_train_samples = train_generator.samples / batch_size\n",
    "nb_validation_samples = validation_generator.samples / batch_size\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
