{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, \\\n",
    "    SeparableConv2D, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import initializers\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "from keras import applications\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "import tensorflow as tf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f83483322b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Session(config=tf.ConfigProto(log_device_placement=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"./dataset/labels_for_test.json\"\n",
    "with open(labels) as label:\n",
    "    data = json.load(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(labels):\n",
    "    data = {}\n",
    "    for key in labels.keys():\n",
    "        if labels[key] not in data:\n",
    "            data.update({labels[key]: []})\n",
    "        data[labels[key]].append(key)\n",
    "    return data\n",
    "data  = data_prepare(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "for i in data:\n",
    "    if len(data[i]) > max_len:\n",
    "        max_len = len(data[i])\n",
    "    train_data.update({i: data[i][:int(0.9*len(data[i]))]})\n",
    "    val_data.update({i: data[i][int(0.9*len(data[i])):]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder with train data stubble prepared\n",
      "Folder with train data goatee_with_moustache prepared\n",
      "Folder with train data shaven prepared\n",
      "Folder with train data moustache prepared\n",
      "Folder with train data classic_short prepared\n",
      "Folder with train data classic_long prepared\n",
      "Folder with train data goatee prepared\n",
      "Folder with train data chin_curtain prepared\n",
      "Folder with validation data stubble prepared\n",
      "Folder with validation data goatee_with_moustache prepared\n",
      "Folder with validation data shaven prepared\n",
      "Folder with validation data moustache prepared\n",
      "Folder with validation data classic_short prepared\n",
      "Folder with validation data classic_long prepared\n",
      "Folder with validation data goatee prepared\n",
      "Folder with validation data chin_curtain prepared\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.8),\n",
    "    sometimes(iaa.Affine(\n",
    "    rotate=(-18, 18),\n",
    ")),\n",
    "])\n",
    "\n",
    "\n",
    "for label in train_data:\n",
    "    if not os.path.exists('dataset/learning_data/' + label):\n",
    "        os.makedirs('dataset/learning_data/' + label)\n",
    "        for i, img_name in enumerate(train_data[label]):\n",
    "            image = cv2.imread('dataset/data_for_test/' +  img_name)\n",
    "            gray = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), (img_width, img_height))\n",
    "            cv2.imwrite('dataset/learning_data/' + label + \"/\" + str(i) +\".jpg\", gray)\n",
    "        for i in range(max_len-len(train_data[label])):\n",
    "            image = cv2.imread('dataset/data_for_test/' + random.choice(train_data[label]))\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            images_aug = seq(images=gray)\n",
    "            cv2.imwrite('dataset/learning_data/' + label + \"/\" + str(len(train_data[label]) + i) +\".jpg\", images_aug)\n",
    "    else:\n",
    "        print(\"Folder with train data {} prepared\".format(label))\n",
    "\n",
    "for label in val_data:\n",
    "    if not os.path.exists('dataset/validation_data/' + label):\n",
    "        os.makedirs('dataset/validation_data/' + label)\n",
    "        for i, img_name in enumerate(val_data[label]):\n",
    "            image = cv2.imread('dataset/data_for_test/' +  img_name)\n",
    "            gray = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), (img_width, img_height))\n",
    "            cv2.imwrite('dataset/validation_data/' + label + \"/\" + str(i) +\".jpg\", gray)\n",
    "    else:\n",
    "        print(\"Folder with validation data {} prepared\".format(label))\n",
    "\n",
    "        \n",
    "del(val_data)\n",
    "del(train_data)\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2408 images belonging to 8 classes.\n",
      "Found 205 images belonging to 8 classes.\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 36s 91ms/step - loss: 2.0154 - acc: 0.2125 - val_loss: 2.1437 - val_acc: 0.1875\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 35s 89ms/step - loss: 1.8263 - acc: 0.2994 - val_loss: 2.0386 - val_acc: 0.1250\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 1.7158 - acc: 0.3606 - val_loss: 2.2071 - val_acc: 0.1250\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 1.6215 - acc: 0.3878 - val_loss: 2.0895 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 1.5508 - acc: 0.4119 - val_loss: 1.9152 - val_acc: 0.3750\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 1.5012 - acc: 0.4372 - val_loss: 2.7304 - val_acc: 0.0625\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 1.4419 - acc: 0.4713 - val_loss: 2.1768 - val_acc: 0.1875\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 37s 91ms/step - loss: 1.3865 - acc: 0.4847 - val_loss: 2.4918 - val_acc: 0.1875\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 1.3469 - acc: 0.4941 - val_loss: 2.2500 - val_acc: 0.3125\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 37s 91ms/step - loss: 1.2984 - acc: 0.5219 - val_loss: 2.3312 - val_acc: 0.1875\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 1.2659 - acc: 0.5381 - val_loss: 2.0832 - val_acc: 0.3750\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 1.2152 - acc: 0.5563 - val_loss: 2.7380 - val_acc: 0.0625\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 1.1742 - acc: 0.5697 - val_loss: 2.1221 - val_acc: 0.1250\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 1.1272 - acc: 0.5731 - val_loss: 2.4056 - val_acc: 0.3125\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 1.1191 - acc: 0.5794 - val_loss: 2.4188 - val_acc: 0.1875\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 1.0676 - acc: 0.6059 - val_loss: 2.3477 - val_acc: 0.1250\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 1.0354 - acc: 0.6212 - val_loss: 2.5929 - val_acc: 0.0625\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 0.9929 - acc: 0.6316 - val_loss: 2.2032 - val_acc: 0.2500\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.9524 - acc: 0.6472 - val_loss: 2.5296 - val_acc: 0.2500\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 36s 89ms/step - loss: 0.9342 - acc: 0.6541 - val_loss: 2.7773 - val_acc: 0.2500\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 0.9111 - acc: 0.6706 - val_loss: 2.4120 - val_acc: 0.3125\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 36s 89ms/step - loss: 0.8671 - acc: 0.6834 - val_loss: 3.1725 - val_acc: 0.1250\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 0.8330 - acc: 0.6969 - val_loss: 2.3446 - val_acc: 0.1875\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 0.8052 - acc: 0.7100 - val_loss: 2.3425 - val_acc: 0.4375\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 0.7828 - acc: 0.7269 - val_loss: 2.3318 - val_acc: 0.3750\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 0.7504 - acc: 0.7259 - val_loss: 2.6799 - val_acc: 0.1250\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 35s 88ms/step - loss: 0.7238 - acc: 0.7381 - val_loss: 2.7055 - val_acc: 0.1875\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 35s 88ms/step - loss: 0.6949 - acc: 0.7459 - val_loss: 2.8046 - val_acc: 0.2500\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 35s 89ms/step - loss: 0.6895 - acc: 0.7559 - val_loss: 3.3484 - val_acc: 0.1250\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 0.6376 - acc: 0.7688 - val_loss: 2.6515 - val_acc: 0.1875\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 36s 89ms/step - loss: 0.6039 - acc: 0.7853 - val_loss: 4.1644 - val_acc: 0.0625\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 36s 89ms/step - loss: 0.5969 - acc: 0.7834 - val_loss: 3.1344 - val_acc: 0.2500\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 0.5788 - acc: 0.7903 - val_loss: 3.3223 - val_acc: 0.3750\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 0.5441 - acc: 0.8078 - val_loss: 3.0487 - val_acc: 0.1875\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.5177 - acc: 0.8169 - val_loss: 3.3043 - val_acc: 0.1250\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 0.4879 - acc: 0.8287 - val_loss: 4.0589 - val_acc: 0.1875\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 0.4747 - acc: 0.8303 - val_loss: 3.3307 - val_acc: 0.1250\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 0.4560 - acc: 0.8381 - val_loss: 2.7434 - val_acc: 0.1875\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 38s 95ms/step - loss: 0.4369 - acc: 0.8447 - val_loss: 3.7366 - val_acc: 0.0625\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 0.4229 - acc: 0.8522 - val_loss: 3.4221 - val_acc: 0.1250\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 0.3809 - acc: 0.8703 - val_loss: 2.9044 - val_acc: 0.2500\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 38s 94ms/step - loss: 0.3909 - acc: 0.8572 - val_loss: 2.4891 - val_acc: 0.4375\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.3590 - acc: 0.8737 - val_loss: 3.9455 - val_acc: 0.1875\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.3357 - acc: 0.8888 - val_loss: 4.5795 - val_acc: 0.2500\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.3234 - acc: 0.8881 - val_loss: 4.8178 - val_acc: 0.0625\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.3011 - acc: 0.8972 - val_loss: 4.3670 - val_acc: 0.0625\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 0.2859 - acc: 0.9053 - val_loss: 3.7262 - val_acc: 0.1875\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 0.2780 - acc: 0.9044 - val_loss: 3.7708 - val_acc: 0.1875\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 0.2616 - acc: 0.9106 - val_loss: 4.5407 - val_acc: 0.1875\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.2515 - acc: 0.9100 - val_loss: 4.5240 - val_acc: 0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f80385f98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = \"dataset/learning_data/\"\n",
    "validation_data_dir = \"dataset/validation_data/\"\n",
    "nb_train_samples = 400\n",
    "nb_validation_samples = 2\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu',\n",
    "          kernel_initializer=initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None))(x)\n",
    "\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# def build_model():\n",
    "#     input_img = Input(shape=(img_width,img_height,3), name='ImageInput')\n",
    "#     x = Conv2D(512, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "#     x = Conv2D(512, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "#     x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "#     x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "#     x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "#     x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "#     x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "#     x = BatchNormalization(name='bn1')(x)\n",
    "#     x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "#     x = BatchNormalization(name='bn2')(x)\n",
    "#     x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "#     x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "#     x = SeparableConv2D(64, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "#     x = BatchNormalization(name='bn3')(x)\n",
    "#     x = SeparableConv2D(64, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "#     x = BatchNormalization(name='bn4')(x)\n",
    "#     x = SeparableConv2D(64, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "#     x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "#     x = Flatten(name='flatten')(x)\n",
    "#     x = Dense(64, activation='relu', name='fc1')(x)\n",
    "#     x = Dropout(0.1, name='dropout2')(x)\n",
    "#     x = Dense(8, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "#     model = Model(inputs=input_img, outputs=x)\n",
    "#     return model\n",
    "# model =  build_model()\n",
    "\n",
    "\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = glob(\"dataset/validation_data/chin_curtain/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([cv2.imread(\"dataset/validation_data/goatee/1.jpg\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 8.3176474e-19,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('beard.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/validation_data/chin_curtain/']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic_long = 4\n",
    "goatee = 5\n",
    "classic_short = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-348897a45b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m history = model.fit_generator(generator=train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n\u001b[0;32m---> 66\u001b[0;31m                                validation_data=(valid_data, valid_labels),callbacks=[es, chkpt])\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"
     ]
    }
   ],
   "source": [
    "class Seq(Sequence):\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.data[idx * self.batch_size:(idx + 1) * self.batch_size][\"image\"]\n",
    "        batch_y = self.data[idx * self.batch_size:(idx + 1) * self.batch_size][\"label\"]\n",
    "\n",
    "        return (np.array([cv2.resize(cv2.imread(file_name, 1), (256, 256)) for file_name in batch_x]),\n",
    "                keras.utils.to_categorical(np.array(batch_y), num_classes =8))\n",
    "\n",
    "def build_model():\n",
    "    input_img = Input(shape=(256,256,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.1, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.1, name='dropout2')(x)\n",
    "    x = Dense(8, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model\n",
    "model =  build_model()\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)\n",
    "\n",
    "batch_size = 8\n",
    "nb_epochs = 20\n",
    "\n",
    "train_data_gen = Seq(data=data, batch_size=batch_size)\n",
    "\n",
    "nb_train_steps = 30\n",
    "\n",
    "history = model.fit_generator(generator=train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
    "                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
